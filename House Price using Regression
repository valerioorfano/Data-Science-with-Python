#Predicting House Price
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import sem
from sklearn.preprocessing import StandardScaler
from sklearn.cross_validation import cross_val_score,KFold,train_test_split
house = pd.read_csv("C:\\Users\\Administrator\\Desktop\\housing.data",delimiter=r"\s+", header=None, names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV'])
#house = pd.read_csv("C:\\Users\\Administrator\\Desktop\\housing.data",usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14], delim_whitespace=True, header=None, names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV'])
#y = house.ix[:,"MEDV"]
y = house.iloc[:,13]
X = house.iloc[:,0:13]
nullX = np.sum([1 for x in X if pd.isnull(x)])
nully = np.sum([1 for x in y if pd.isnull(x)])
print "Null Values in X={0:.0f} and Null values in y={1:.0f}".format(nullX, nully)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)
X_train_stand = StandardScaler().fit(X_train).transform(X_train)
y_train_stand = StandardScaler().fit(y_train).transform(y_train)
X_test_stand = StandardScaler().fit(X_test).transform(X_test)
y_test_stand = StandardScaler().fit(y_test).transform(y_test)

def x_validation(X,y,clf,K,alg):
    cv = KFold(len(y),n_folds=K,shuffle=True,random_state=42,)
    scores = cross_val_score(estimator=clf, X=X, y=y, cv=cv)
    print "==================================================================="
    print alg + " : R-square Mean using 5-Fold: {0:.3f} +/- {1:.3f}".format(np.mean(scores),sem(scores))

#Let's try first the linear model
from sklearn.linear_model import SGDRegressor
clf_sgd = SGDRegressor(loss='squared_loss',random_state=42)
clf_sgd.fit(X_train_stand,y_train_stand)    
x_validation(X_train_stand,y_train_stand,clf_sgd,5, "SGD") 
#R-square Mean using 5-Fold: 0.680 +/- 0.058
#Let's try SVM with kernel = linear
from sklearn.svm import SVR
clf_svr_lin = SVR(kernel='linear', random_state=42)
clf_svr_lin.fit(X_train_stand,y_train_stand)
x_validation(X_train_stand,y_train_stand,clf_svr_lin,5, "SVR_LINEAR") 
#===================================================================
#SGD : R-square Mean using 5-Fold: 0.682 +/- 0.063
#===================================================================
#SVR : R-square Mean using 5-Fold: 0.671 +/- 0.065
#Not a big deal
clf_svr_poly = SVR(kernel='poly', random_state=42)
clf_svr_poly.fit(X_train_stand,y_train_stand)
x_validation(X_train_stand,y_train_stand,clf_svr_poly,5, "SVR_POLYNOMIAL") 
#SGD : R-square Mean using 5-Fold: 0.698 +/- 0.024
#===================================================================
#SVR_LINEAR : R-square Mean using 5-Fold: 0.667 +/- 0.029
#===================================================================
#SVR_POLYNOMIAL : R-square Mean using 5-Fold: 0.786 +/- 0.019
clf_svr_rbf = SVR(kernel='rbf', random_state=42)
clf_svr_rbf.fit(X_train_stand,y_train_stand)
x_validation(X_train_stand,y_train_stand,clf_svr_rbf,5, "SVR_RBF") 
#===================================================================
#SGD : R-square Mean using 5-Fold: 0.716 +/- 0.063
#===================================================================
#SVR_LINEAR : R-square Mean using 5-Fold: 0.704 +/- 0.064
#===================================================================
#SVR_POLYNOMIAL : R-square Mean using 5-Fold: 0.731 +/- 0.029
#===================================================================
#SVR_RBF : R-square Mean using 5-Fold: 0.803 +/- 0.044
#Let's try with RandomForest
from sklearn.ensemble import RandomForestRegressor
clf_rf = RandomForestRegressor()
clf_rf.fit(X_train_stand,y_train_stand)
x_validation(X_train_stand,y_train_stand,clf_rf,5, "SVR_RandomF") 
#===================================================================
#SGD : R-square Mean using 5-Fold: 0.692 +/- 0.037
#===================================================================
#SVR_LINEAR : R-square Mean using 5-Fold: 0.680 +/- 0.044
#===================================================================
#SVR_POLYNOMIAL : R-square Mean using 5-Fold: 0.680 +/- 0.070
#===================================================================
#SVR_RBF : R-square Mean using 5-Fold: 0.781 +/- 0.021
#===================================================================
#SVR_RandomF : R-square Mean using 5-Fold: 0.829 +/- 0.015
#===================================================================
#SVR_ExtraTreesR : R-square Mean using 5-Fold: 0.837 +/- 0.018
#Let's try with ExtraTreesRegressor
from sklearn.ensemble import ExtraTreesRegressor
clf_et = ExtraTreesRegressor()
clf_et.fit(X_train_stand,y_train_stand)
x_validation(X_train_stand,y_train_stand,clf_et,5, "SVR_ExtraTreesR") 
#===================================================================
#SGD : R-square Mean using 5-Fold: 0.671 +/- 0.027
#===================================================================
#SVR_LINEAR : R-square Mean using 5-Fold: 0.650 +/- 0.041
#===================================================================
#SVR_POLYNOMIAL : R-square Mean using 5-Fold: 0.605 +/- 0.099
#===================================================================
#SVR_RBF : R-square Mean using 5-Fold: 0.772 +/- 0.028
#===================================================================
#SVR_RandomF : R-square Mean using 5-Fold: 0.807 +/- 0.029
#===================================================================
#SVR_ExtraTreesR : R-square Mean using 5-Fold: 0.835 +/- 0.030
print sort(zip(clf_et.feature_importances_,X.columns.values), axis=0)
#[['0.00168238858122' 'AGE']
# ['0.00219091920988' 'B']
# ['0.00578282921896' 'CHAS']
# ['0.00719983817171' 'CRIM']
# ['0.0096684580973' 'DIS']
# ['0.0132246117316' 'INDUS']
# ['0.0271658188306' 'LSTAT']
# ['0.0321977534763' 'NOX']
# ['0.0514845790226' 'PTRATIO']
# ['0.0698421674248' 'RAD']
# ['0.103207363872' 'RM']
# ['0.271185135531' 'TAX']
# ['0.405168136832' 'ZN']]
#ZN is th emost important feature, age the less.
from sklearn import metrics
def evaluation(X,y,clf, datatype):
    y_pred = clf.predict(X_test)
    print datatype + ": coefficient of determination: {0:.3f}".format(metrics.r2_score(y_test,y_pred))
    print datatype + ": MSE: {0:.3f}".format(metrics.mean_squared_error(y_test,y_pred))
evaluation(X_test_stand,y_test_stand,clf_et,"Test Data")
